过于自负
========
     说白了, 就是机器学习模型于自信. 已经到了自负的阶段了. 那自负的坏处, 大家也知道, 就是在自己的小圈子里表现非凡, 
     不过在现实的大圈子里却往往处处碰壁. 所以在这个简介里, 我们把自负和过拟合画上等号.
     
 回归分类的过拟合
 ===============
    机器学习模型的自负又表现在哪些方面呢. 这里是一些数据. 如果要你画一条线来描述这些数据, 大多数人都会这么画. 对这条
    线也是我们希望机器也能学出来的一条用来总结这些数据的线. 这时蓝线与数据的总误差可能是10. 可是有时候, 机器过于纠结
    这误差值, 他想把误差减到更小, 来完成他对这一批数据的学习使命. 所以, 他学到的可能会变成这样 . 它几乎经过了每一个
    数据点, 这样, 误差值会更小 . 可是误差越小就真的好吗? 看来我们的模型还是太天真了. 当我拿这个模型运用在现实中的时候,
    他的自负就体现出来. 小二, 来一打现实数据 . 这时, 之前误差大的蓝线误差基本保持不变 .误差小的 红线误差值突然飙高 , 
    自负的红线再也骄傲不起来, 因为他不能成功的表达除了训练数据以外的其他数据. 这就叫做过拟合. Overfitting.
    
解决方法
========
    方法一: 增加数据量,大部分过拟合产生的原因是因为数据量太少了.如果我们有成千上万的数据,红线也会慢慢被拉直,变得没那么扭曲. 
    -----------------
    方法二: 运用正规化. L1, l2 regularization等等, 这些方法适用于大多数的机器学习, 包括神经网络. 他们的做法大同小异, 我们
    -----------------
    简化机器学习的关键公式为 y=Wx . W为机器需要学习到的各种参数. 在过拟合中, W 的值往往变化得特别大或特别小. 为了不让W变化
                          -----                                                                      ------------ 
    太大, 我们在计算误差上做些手脚. 原始的 cost 误差是这样计算, cost = 预测值-真实值的平方. 如果 W 变得太大, 我们就让 cost 
    ----                                                   --------------------------
    也跟着变大, 变成一种惩罚机制. 所以我们把 W 自己考虑进来. 这里 abs 是绝对值. 这一种形式的 正规化, 叫做 l1 正规化. L2 正
                                                                                                  =========  =====
    规化和 l1 类似, 只是绝对值换成了平方. 其他的l3, l4 也都是换成了立方和4次方等等. 形式类似. 用这些方法,我们就能保证让学出
    ====
    来的线条不会过于扭曲.
    
            L1:     cost = (Wx - really) ^ 2 + abs(W)
            
            L2:     cost = (Wx - really) ^ 2 + (W) ^ 2
    
    还有一种专门用在神经网络的正规化的方法, 叫作 dropout. 在训练的时候, 我们随机忽略掉一些神经元和神经联结 , 是这个神经网络变
                                             ========
    得”不完整”. 用一个不完整的神经网络训练一次.

    到第二次再随机忽略另一些, 变成另一个不完整的神经网络. 有了这些随机 drop 掉的规则, 我们可以想象其实每次训练的时候, 我们都让
    
    每一次预测结果都不会依赖于其中某部分特定的神经元. 像l1, l2正规化一样, 过度依赖的 W , 也就是训练参数的数值会很大, l1, l2会
    
    惩罚这些大的 参数. Dropout 的做法是从根本上让神经网络没机会过度依赖.
    
实践
====
     观察train和test的学习曲线，如果train的正确率很低，则肯定underfitting，如果train的很高，但是test比train的低，则是overfitting
     ---------------------------------------------------------------------------------------------------------------------
     示例： 利用drop_out防止overfitting
     ---------------------------------
     定义变量 keep_prob, 在layer中加入对 dropout 的调用，然后在sess.run的feed_dict传入 keep_prob
     ----------------------------------------------------------------------------------------
          """
          Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.
          """
          from __future__ import print_function
          import tensorflow as tf
          from sklearn.datasets import load_digits
          from sklearn.model_selection import train_test_split
          from sklearn.preprocessing import LabelBinarizer

          # load data
          digits = load_digits()
          X = digits.data
          y = digits.target
          y = LabelBinarizer().fit_transform(y)
          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)


          def add_layer(inputs, in_size, out_size, layer_name, activation_function=None, ):
              # add one more layer and return the output of this layer
              Weights = tf.Variable(tf.random_normal([in_size, out_size]))
              biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, )
              Wx_plus_b = tf.matmul(inputs, Weights) + biases
              # here to dropout
              
              Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)
              #           -----------------------------------
              
              if activation_function is None:
                  outputs = Wx_plus_b
              else:
                  outputs = activation_function(Wx_plus_b, )
                  
              # 好像tensorflow中必须要有higtogram，不能只用scalar
              tf.summary.histogram(layer_name + '/outputs', outputs)
              # -------------------------------------------------------
              
              return outputs

          # keep_prob drop_out参数 0.6则表明 保留60%
          # define placeholder for inputs to network
          keep_prob = tf.placeholder(tf.float32)
          # -------------------------------------
          
          xs = tf.placeholder(tf.float32, [None, 64])  # 8x8
          ys = tf.placeholder(tf.float32, [None, 10])

          # add output layer
          l1 = add_layer(xs, 64, 50, 'l1', activation_function=tf.nn.tanh)
          prediction = add_layer(l1, 50, 10, 'l2', activation_function=tf.nn.softmax)

          # the loss between prediction and real data
          cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),
                                                        reduction_indices=[1]))  # loss
          tf.summary.scalar('loss', cross_entropy)
          train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

          sess = tf.Session()
          merged = tf.summary.merge_all()
          # --------------------------------
          # summary writer goes in here
          train_writer = tf.summary.FileWriter("logs/train", sess.graph)
          test_writer = tf.summary.FileWriter("logs/test", sess.graph)

          # tf.initialize_all_variables() no long valid from
          # 2017-03-02 if using tensorflow >= 0.12
          if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:
              init = tf.initialize_all_variables()
          else:
              init = tf.global_variables_initializer()
          sess.run(init)
          for i in range(500):
          
              # here to determine the keeping probability
              sess.run(train_step, feed_dict={xs: X_train, ys: y_train, keep_prob: 0.5})
              #                                                         -----------------
          
              if i % 50 == 0:
                  # record loss
                  train_result = sess.run(merged, feed_dict={xs: X_train, ys: y_train, keep_prob: 1})
                  #                                                                   --------------
                  test_result = sess.run(merged, feed_dict={xs: X_test, ys: y_test, keep_prob: 1})
                  #                                                                 -------------
                  train_writer.add_summary(train_result, i)
                  test_writer.add_summary(test_result, i)
     
    
    
    
    
