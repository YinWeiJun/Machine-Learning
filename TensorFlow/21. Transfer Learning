迁移学习
========
    “为了偷懒, 在训练好了的模型上接着训练其他内容, 充分使用原模型的理解力”. 有时候也是为了避免再次花费特别长的时间重复训练大型模型.
    
    CNN 通常都是大型模型, 下面我们拿 CNN 来举个例子. 我训练好了一个区分男人和女人的 CNN. 接着来了个任务, 说我下个任务是区分照片中
    
    人的年龄. 这看似完全不相干的两个模型, 但是我们却可以运用到迁移学习, 让之前那个 CNN 当我们的初始模型, 因为区分男女的 CNN 已经对
    
    人类有了理解. 基于这个理解开始训练, 总比完全重新开始训练强. 但是如果你下一个任务是区分飞机和大象. 这个 CNN 可能就没那么有用了, 
    
    因为这个 CNN 可能并没有对飞机大象有任何的理解.

    这一次, 我们就来迁移一个图片分类的 CNN (VGG). 这个 VGG 在1000个类别中训练过. 我们提取这个 VGG 前面的 Conv layers, 重新组建后
    
    面的 fully connected layers, 让它做一个和分类完全不相干的事. 我们在网上下载那1000个分类数据中的猫和老虎的图片, 然后伪造一些猫
    
    和老虎长度的数据. 最后做到让迁移后的网络分辨出猫和老虎的长度 (regressor).
    
下载数据
========
    为了达到这次的目的, 我们不需要下载所有的1000个分类的所有图片, 只要找到自己感兴趣的类就好 (老虎和猫). 我选老虎和猫的目的就是因为
    
    他们是近亲, 还是有点像的, 可以增加点难度. 如果是飞机和大象的话, 学习难度就被降低了.
    
    老虎： https://morvanzhou.github.io/static/results/tensorflow/imagenet_tiger.txt
    猫咪： https://morvanzhou.github.io/static/results/tensorflow/imagenet_kittycat.txt
    
迁移 VGG
========
    处理好图片后, 我们可以开始弄 VGG 的 pre-trained model. 我使用的是machrisaa 改写的 VGG16 的代码. 和他提供的 VGG16 train 好了
    
    的 model parameters, 你可以在 https://mega.nz/#!YU1FWJrA!O1ywiCS2IiOlUCtCpI6HTJOMrneN-Qdv3ywQP5poecM 下载这些 parameters。
    
    做好准备, 这个 parameter 文件有500+MB. 可见一般 CNN 的 model 有多大.
    
    为了做迁移学习, 我对他的 tensorflow VGG16 代码进行了改写. 保留了所有 Conv 和 pooling 层, 将后面的所有 fc 层拆了, 改成可以被 train
    
    的两层, 输出一个数字, 这个数字代表了这只猫或老虎的长度.

            class Vgg16:
                def __init__():
                    # ...前面的层
                    pool5 = self.max_pool(conv5_3, 'pool5')

                    # pool5 是最后的 conv 出来的结果
                    self.flatten = tf.reshape(pool5, [-1, 7*7*512])
                    self.fc6 = tf.layers.dense(self.flatten, 256, tf.nn.relu, name='fc6')
                    self.out = tf.layers.dense(self.fc6, 1, name='out')
                    
    在 self.flatten 之前的 layers, 都是不能被 train 的. 而 tf.layers.dense() 建立的 layers 是可以被 train 的. 到时候我们 train 
    
    好了, 再定义一个 Saver 来保存由 tf.layers.dense() 建立的 parameters.

            class Vgg16:
                ...
                def save(self, path='./for_transfer_learning/model/transfer_learn'):
                    saver = tf.train.Saver()
                    saver.save(self.sess, path, write_meta_graph=False)
                    
训练
====
    因为有了训练好了的 VGG16, 你就能将 VGG16 的 Conv 层想象成是一个 feature extractor, 提取或压缩图片中的特征. 和 Autoencoder 中的 
    
    encoder 类似. 用这些提取的特征来训练后面的 regressor. 具体代码在这, 下面是简写版.

            def train():
                xs, ys = ...

                vgg = Vgg16(vgg16_npy_path='./for_transfer_learning/vgg16.npy')
                print('Net built')
                for i in range(100):
                    b_idx = np.random.randint(0, len(xs), 6)
                    train_loss = vgg.train(xs[b_idx], ys[b_idx])
                    print(i, 'train loss: ', train_loss)

            vgg.save('./for_transfer_learning/model/transfer_learn')
            
    这里我只 train 了 100次, 如果是重新开始 train 一个 CNN, 100次绝对少了. 而且我使用的是只有 CPU 的电脑, 不好意思, 我暂时没有合适的 
    
    GPU… 所以你暂时在 莫烦Python 中基本找不到关于图像处理的教程… 不过! 正因为 transfer learning 让我不用从头 train CNN, 所以我做了这
    
    个教程! 否则, 我想用我的 CPU, 估计得一周才能 train 出来这个 VGG 吧.
    
测试
====
    我们现在已经迁移好了, train 好了后面的 fc layers, 也保存了后面的 fc 参数. 接着我们提取原始的 VGG16 前半部分参数和 train 好的后半
    
    部分参数. 进行测试.

            def eval():
                vgg = Vgg16(vgg16_npy_path='./for_transfer_learning/vgg16.npy',
                            restore_from='./for_transfer_learning/model/transfer_learn')
                vgg.predict(
                    ['./for_transfer_learning/data/kittycat/000129037.jpg',
                    './for_transfer_learning/data/tiger/391412.jpg'])
                    
    可以想象, 要让 VGG 达到这个目的, VGG必须懂得区分哪些是猫, 哪些是老虎, 而这个认知, 在原始的 VGG conv 层中就已经学出来了. 所以如果我们
    
    拆了后面的层, 将后面的 classifier 变成 regressor, 花费相当少的时间就能训练好.

    迁移学习的玩法除了这样, 还有很多种其他的玩法, 我在这个短视频中介绍了一些. 迁移学习还有一些细节的地方也可以在这里关注一下, 比如什么时候
    
    要稍微 train 一下前面的 conv layers, 什么时候要完全固定住前面的 conv layers.
                
                
完整代码
========
            from urllib.request import urlretrieve
            import os
            import numpy as np
            import tensorflow as tf
            import skimage.io
            import skimage.transform
            import matplotlib.pyplot as plt


            def download():     # download tiger and kittycat image
                categories = ['tiger', 'kittycat']
                for category in categories:
                    os.makedirs('./for_transfer_learning/data/%s' % category, exist_ok=True)
                    with open('./for_transfer_learning/imagenet_%s.txt' % category, 'r') as file:
                        urls = file.readlines()
                        n_urls = len(urls)
                        for i, url in enumerate(urls):
                            try:
                                urlretrieve(url.strip(), './for_transfer_learning/data/%s/%s' % (category, url.strip().split('/')[-1]))
                                print('%s %i/%i' % (category, i, n_urls))
                            except:
                                print('%s %i/%i' % (category, i, n_urls), 'no image')


            def load_img(path):
                img = skimage.io.imread(path)
                img = img / 255.0
                # print "Original Image Shape: ", img.shape
                # we crop image from center
                short_edge = min(img.shape[:2])
                yy = int((img.shape[0] - short_edge) / 2)
                xx = int((img.shape[1] - short_edge) / 2)
                crop_img = img[yy: yy + short_edge, xx: xx + short_edge]
                # resize to 224, 224
                resized_img = skimage.transform.resize(crop_img, (224, 224))[None, :, :, :]   # shape [1, 224, 224, 3]
                return resized_img


            def load_data():
                imgs = {'tiger': [], 'kittycat': []}
                for k in imgs.keys():
                    dir = './for_transfer_learning/data/' + k
                    for file in os.listdir(dir):
                        if not file.lower().endswith('.jpg'):
                            continue
                        try:
                            resized_img = load_img(os.path.join(dir, file))
                        except OSError:
                            continue
                        imgs[k].append(resized_img)    # [1, height, width, depth] * n
                        if len(imgs[k]) == 400:        # only use 400 imgs to reduce my memory load
                            break
                # fake length data for tiger and cat
                tigers_y = np.maximum(20, np.random.randn(len(imgs['tiger']), 1) * 30 + 100)
                cat_y = np.maximum(10, np.random.randn(len(imgs['kittycat']), 1) * 8 + 40)
                return imgs['tiger'], imgs['kittycat'], tigers_y, cat_y


            class Vgg16:
                vgg_mean = [103.939, 116.779, 123.68]

                def __init__(self, vgg16_npy_path=None, restore_from=None):
                    # pre-trained parameters
                    try:
                        self.data_dict = np.load(vgg16_npy_path, encoding='latin1').item()
                    except FileNotFoundError:
                        print('Please download VGG16 parameters from here https://mega.nz/#!YU1FWJrA!O1ywiCS2IiOlUCtCpI6HTJOMrneN-Qdv3ywQP5poecM\nOr from my Baidu Cloud: https://pan.baidu.com/s/1Spps1Wy0bvrQHH2IMkRfpg')

                    self.tfx = tf.placeholder(tf.float32, [None, 224, 224, 3])
                    self.tfy = tf.placeholder(tf.float32, [None, 1])

                    # Convert RGB to BGR
                    red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=self.tfx * 255.0)
                    bgr = tf.concat(axis=3, values=[
                        blue - self.vgg_mean[0],
                        green - self.vgg_mean[1],
                        red - self.vgg_mean[2],
                    ])

                    # pre-trained VGG layers are fixed in fine-tune
                    conv1_1 = self.conv_layer(bgr, "conv1_1")
                    conv1_2 = self.conv_layer(conv1_1, "conv1_2")
                    pool1 = self.max_pool(conv1_2, 'pool1')

                    conv2_1 = self.conv_layer(pool1, "conv2_1")
                    conv2_2 = self.conv_layer(conv2_1, "conv2_2")
                    pool2 = self.max_pool(conv2_2, 'pool2')

                    conv3_1 = self.conv_layer(pool2, "conv3_1")
                    conv3_2 = self.conv_layer(conv3_1, "conv3_2")
                    conv3_3 = self.conv_layer(conv3_2, "conv3_3")
                    pool3 = self.max_pool(conv3_3, 'pool3')

                    conv4_1 = self.conv_layer(pool3, "conv4_1")
                    conv4_2 = self.conv_layer(conv4_1, "conv4_2")
                    conv4_3 = self.conv_layer(conv4_2, "conv4_3")
                    pool4 = self.max_pool(conv4_3, 'pool4')

                    conv5_1 = self.conv_layer(pool4, "conv5_1")
                    conv5_2 = self.conv_layer(conv5_1, "conv5_2")
                    conv5_3 = self.conv_layer(conv5_2, "conv5_3")
                    pool5 = self.max_pool(conv5_3, 'pool5')

                    # detach original VGG fc layers and
                    # reconstruct your own fc layers serve for your own purpose
                    self.flatten = tf.reshape(pool5, [-1, 7*7*512])
                    self.fc6 = tf.layers.dense(self.flatten, 256, tf.nn.relu, name='fc6')
                    self.out = tf.layers.dense(self.fc6, 1, name='out')

                    self.sess = tf.Session()
                    if restore_from:
                        saver = tf.train.Saver()
                        saver.restore(self.sess, restore_from)
                    else:   # training graph
                        self.loss = tf.losses.mean_squared_error(labels=self.tfy, predictions=self.out)
                        self.train_op = tf.train.RMSPropOptimizer(0.001).minimize(self.loss)
                        self.sess.run(tf.global_variables_initializer())

                def max_pool(self, bottom, name):
                    return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)

                def conv_layer(self, bottom, name):
                    with tf.variable_scope(name):   # CNN's filter is constant, NOT Variable that can be trained
                        conv = tf.nn.conv2d(bottom, self.data_dict[name][0], [1, 1, 1, 1], padding='SAME')
                        lout = tf.nn.relu(tf.nn.bias_add(conv, self.data_dict[name][1]))
                        return lout

                def train(self, x, y):
                    loss, _ = self.sess.run([self.loss, self.train_op], {self.tfx: x, self.tfy: y})
                    return loss

                def predict(self, paths):
                    fig, axs = plt.subplots(1, 2)
                    for i, path in enumerate(paths):
                        x = load_img(path)
                        length = self.sess.run(self.out, {self.tfx: x})
                        axs[i].imshow(x[0])
                        axs[i].set_title('Len: %.1f cm' % length)
                        axs[i].set_xticks(()); axs[i].set_yticks(())
                    plt.show()

                def save(self, path='./for_transfer_learning/model/transfer_learn'):
                    saver = tf.train.Saver()
                    saver.save(self.sess, path, write_meta_graph=False)


            def train():
                tigers_x, cats_x, tigers_y, cats_y = load_data()

                # plot fake length distribution
                plt.hist(tigers_y, bins=20, label='Tigers')
                plt.hist(cats_y, bins=10, label='Cats')
                plt.legend()
                plt.xlabel('length')
                plt.show()

                xs = np.concatenate(tigers_x + cats_x, axis=0)
                ys = np.concatenate((tigers_y, cats_y), axis=0)

                vgg = Vgg16(vgg16_npy_path='./for_transfer_learning/vgg16.npy')
                print('Net built')
                for i in range(100):
                    b_idx = np.random.randint(0, len(xs), 6)
                    train_loss = vgg.train(xs[b_idx], ys[b_idx])
                    print(i, 'train loss: ', train_loss)

                vgg.save('./for_transfer_learning/model/transfer_learn')      # save learned fc layers


            def eval():
                vgg = Vgg16(vgg16_npy_path='./for_transfer_learning/vgg16.npy',
                            restore_from='./for_transfer_learning/model/transfer_learn')
                vgg.predict(
                    ['./for_transfer_learning/data/kittycat/000129037.jpg', './for_transfer_learning/data/tiger/391412.jpg'])


            if __name__ == '__main__':
                # download()
                # train()
                eval()
    
    
    
    
